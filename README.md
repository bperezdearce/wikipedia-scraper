# Wikipedia Scraper

Este es un scraper de Wikipedia desarrollado con **Scrapy** y **BeautifulSoup**. Extrae los t√≠tulos, primeros p√°rrafos y enlaces de los 10 art√≠culos destacados en Wikipedia en espa√±ol.

## Caracter√≠sticas

- Extrae los primeros 10 art√≠culos destacados.
- Obtiene el t√≠tulo y el primer p√°rrafo de cada art√≠culo.
- Guarda los datos en formato JSON.
- Limpieza autom√°tica de espacios invisibles y referencias num√©ricas.

## Requisitos

Aseg√∫rate de tener instalado:
- Python 3.8+ üêç
- Scrapy (pip3 install scrapy)
- BeautifulSoup (pip3 install beautifulsoup4)
- Git (para clonar el repositorio)

## Instalaci√≥n

1Ô∏è‚É£ Clona este repositorio:
```
git clone https://github.com/bperezdearce/wikipedia-scraper.git
cd wikipedia-scraper
```
2Ô∏è‚É£ Crea un entorno virtual (opcional, recomendado):
```
python -m venv .venv
source .venv/bin/activate  # En Mac/Linux
.venv\Scripts\activate  # En Windows
```
3Ô∏è‚É£ Instala las dependencias:
```
pip install -r requirements.txt
```

## C√≥mo Ejecutarlo

Para ejecutar el scraper y guardar la salida en un archivo JSON:
```
scrapy crawl wikipedia -o articulos.json
```
Despu√©s de ejecutarlo, encontrar√°s un archivo articulos.json con los resultados.

## Ejemplo de Salida JSON
```
[
    {
        "titulo": "Carne",
        "primer_parrafo": "La carne es el tejido muscular de los animales que se consume como alimento...",
        "url": "https://es.wikipedia.org/wiki/Carne"
    },
    {
        "titulo": "Historia de la hamburguesa",
        "primer_parrafo": "Los or√≠genes de la hamburguesa son inciertos, pero se sabe que fue elaborada en el siglo XIX...",
        "url": "https://es.wikipedia.org/wiki/Historia_de_la_hamburguesa"
    }
]
```

## Posibles Mejoras

- Exportar datos a CSV o base de datos.
- Mejorar la extracci√≥n de m√°s secciones de Wikipedia.
- Implementar Scrapy Pipelines para limpiar los datos antes de guardarlos.
