# Wikipedia Scraper ğŸ•µï¸â€â™€ï¸

Este es un scraper de Wikipedia desarrollado con Scrapy y BeautifulSoup. Extrae los tÃ­tulos, primeros pÃ¡rrafos y enlaces de los 10 artÃ­culos destacados en Wikipedia en espaÃ±ol. ğŸ“œâœ¨

ğŸš€ CaracterÃ­sticas

Extrae los primeros 10 artÃ­culos destacados.

Obtiene el tÃ­tulo y el primer pÃ¡rrafo de cada artÃ­culo.

Guarda los datos en formato JSON.

Limpieza automÃ¡tica de espacios invisibles y referencias numÃ©ricas.

ğŸ“Œ Requisitos

AsegÃºrate de tener instalado:

Python 3.8+ ğŸ

Scrapy (pip install scrapy)

BeautifulSoup (pip install beautifulsoup4)

Git (para clonar el repositorio)

ğŸ”§ InstalaciÃ³n

1ï¸âƒ£ Clona este repositorio:

git clone https://github.com/bperezdearce/wikipedia-scraper.git
cd wikipedia-scraper

2ï¸âƒ£ Crea un entorno virtual (opcional, recomendado):

python -m venv .venv
source .venv/bin/activate  # En Mac/Linux
.venv\Scripts\activate  # En Windows

3ï¸âƒ£ Instala las dependencias:

pip install -r requirements.txt

ğŸƒâ€â™€ï¸ CÃ³mo Ejecutarlo

Para ejecutar el scraper y guardar la salida en un archivo JSON:

scrapy crawl wikipedia -o articulos.json

DespuÃ©s de ejecutarlo, encontrarÃ¡s un archivo articulos.json con los resultados.

ğŸ“œ Ejemplo de Salida JSON

[
    {
        "titulo": "Carne",
        "primer_parrafo": "La carne es el tejido muscular de los animales que se consume como alimento...",
        "url": "https://es.wikipedia.org/wiki/Carne"
    },
    {
        "titulo": "Historia de la hamburguesa",
        "primer_parrafo": "Los orÃ­genes de la hamburguesa son inciertos, pero se sabe que fue elaborada en el siglo XIX...",
        "url": "https://es.wikipedia.org/wiki/Historia_de_la_hamburguesa"
    }
]

ğŸ’¡ Posibles Mejoras

ğŸ”¹ Exportar datos a CSV o base de datos.ğŸ”¹ Mejorar la extracciÃ³n de mÃ¡s secciones de Wikipedia.ğŸ”¹ Implementar Scrapy Pipelines para limpiar los datos antes de guardarlos.
